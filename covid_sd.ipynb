{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.2.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4045: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-836e7fb33c85>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m840\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m480\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[0mboxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0modapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocessFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.2.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4045: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import time\n",
    "from scipy.spatial import distance as dist\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "class DetectorAPI:\n",
    "    def __init__(self, path_to_ckpt):\n",
    "        self.path_to_ckpt = path_to_ckpt\n",
    "\n",
    "        self.detection_graph = tf.Graph()\n",
    "        with self.detection_graph.as_default():\n",
    "            od_graph_def = tf.GraphDef()\n",
    "            with tf.gfile.GFile(self.path_to_ckpt, 'rb') as fid:\n",
    "                serialized_graph = fid.read()\n",
    "                od_graph_def.ParseFromString(serialized_graph)\n",
    "                tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "        self.default_graph = self.detection_graph.as_default()\n",
    "        self.sess = tf.Session(graph=self.detection_graph)\n",
    "\n",
    "        # Definite input and output Tensors for detection_graph\n",
    "        self.image_tensor = self.detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "        # Each box represents a part of the image where a particular object was detected.\n",
    "        self.detection_boxes = self.detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "        # Each score represent how level of confidence for each of the objects.\n",
    "        # Score is shown on the result image, together with the class label.\n",
    "        self.detection_scores = self.detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "        self.detection_classes = self.detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "        self.num_detections = self.detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "    def processFrame(self, image):\n",
    "        # Expand dimensions since the trained_model expects images to have shape: [1, None, None, 3]\n",
    "        image_np_expanded = np.expand_dims(image, axis=0)\n",
    "        # Actual detection.\n",
    "        start_time = time.time()\n",
    "        (boxes, scores, classes, num) = self.sess.run(\n",
    "            [self.detection_boxes, self.detection_scores, self.detection_classes, self.num_detections],\n",
    "            feed_dict={self.image_tensor: image_np_expanded})\n",
    "        end_time = time.time()\n",
    "\n",
    "        #print(\"Elapsed Time:\", end_time-start_time)\n",
    "\n",
    "        im_height, im_width,_ = image.shape\n",
    "        boxes_list = [None for i in range(boxes.shape[1])]\n",
    "        for i in range(boxes.shape[1]):\n",
    "            boxes_list[i] = (int(boxes[0,i,0] * im_height),\n",
    "                        int(boxes[0,i,1]*im_width),\n",
    "                        int(boxes[0,i,2] * im_height),\n",
    "                        int(boxes[0,i,3]*im_width))\n",
    "\n",
    "        return boxes_list, scores[0].tolist(), [int(x) for x in classes[0].tolist()], int(num[0])\n",
    "\n",
    "    def close(self):\n",
    "        self.sess.close()\n",
    "        self.default_graph.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model_path = './faster_rcnn_inception_v2_coco_2018_01_28/frozen_inference_graph.pb'\n",
    "    odapi = DetectorAPI(path_to_ckpt=model_path)\n",
    "    threshold = 0.75\n",
    "    cap = cv2.VideoCapture('inpu2.mp4')\n",
    "    \n",
    "\n",
    "    pts_src = np.float32([550, 1, 1335, 90, 1140, 750, 0,270]).reshape(4, 1, -1)\n",
    "    pts_dst = np.float32([0, 0, 336, 0, 336, 388,0, 388]).reshape(4, 1, -1)\n",
    "    h = cv2.findHomography(pts_src, pts_dst,cv2.RANSAC)[0]\n",
    "    \n",
    "# multi point prospective\n",
    "#     pts_src = np.float32([617, 1, 1360, 1, 960, 765, 0,313]).reshape(4, 1, -1)\n",
    "#     pts_dst = np.float32([0, 0, 336, 0, 336, 388,0, 388]).reshape(4, 1, -1)\n",
    "#     h = cv2.findHomography(pts_src, pts_dst,cv2.RANSAC)[0]\n",
    "    \n",
    "# 4 point prospective\n",
    "#     pts_src = np.float32([517, 7, 1361, 27, 1087, 767, 0, 457]).reshape(4, 1, -1)\n",
    "#     pts_dst = np.float32([0, 0, 336, 0, 336, 388,0, 388]).reshape(4, 1, -1)\n",
    "#     h = cv2.findHomography(pts_src, pts_dst)[0]\n",
    "    \n",
    "    \n",
    "    out = cv2.VideoWriter(\"output2.avi\",cv2.VideoWriter_fourcc(*\"MJPG\") ,30,(840, 480))\n",
    "    out_2d = cv2.VideoWriter(\"2d2.avi\",cv2.VideoWriter_fourcc(*\"MJPG\") ,30,(336, 388))\n",
    "    while True:\n",
    "        r, img = cap.read()\n",
    "        img = cv2.resize(img, (840, 480))\n",
    "        \n",
    "        boxes, scores, classes, num = odapi.processFrame(img)\n",
    "\n",
    "        # Visualization of the results of a detection.\n",
    "        dct={}\n",
    "        two_d = cv2.imread('2d.jpg')\n",
    "        for i in range(len(boxes)):\n",
    "            # Class 1 represents human\n",
    "            if classes[i] == 1 and scores[i] > threshold:\n",
    "                box = boxes[i]\n",
    "                y_cntr  = int((box[0] + box[2]) / 2)\n",
    "                x_cntr  = int((box[1] + box[3]) / 2)\n",
    "                dct.update( {i : [x_cntr,y_cntr,[box]]} )\n",
    "                \n",
    "                \n",
    "                blurred_img = cv2.GaussianBlur(img, (11, 11), 0)\n",
    "                mask = np.zeros((img.shape), dtype=np.uint8)\n",
    "                mask =  cv2.rectangle(mask,(box[1],box[0]),(box[3],box[2]),(255,255,255),-1)\n",
    "                img = np.where(mask==np.array([255, 255, 255]), blurred_img,img)\n",
    "                \n",
    "                \n",
    "                \n",
    "                cv2.rectangle(img,(box[1],box[0]),(box[3],box[2]),(255,0,0),1)\n",
    "                \n",
    "                cv2.ellipse(img, (x_cntr,box[2]), ((box[2] - box[0]),int((box[2] - box[0])/3)), 0, 0,360, (255,0,0), 1)\n",
    "#                 cv2.circle(img, (x_cntr,y_cntr), 2, (255,25,0), -1) \n",
    "                \n",
    "\n",
    "                pt = np.float32([x_cntr, y_cntr]).reshape(1, 1, -1)\n",
    "                td_point = cv2.perspectiveTransform(pt, h)\n",
    "                cv2.circle(two_d, (int(td_point[0][0][0]),int(td_point[0][0][1])), 3, (255,25,0), -1)\n",
    "                cv2.circle(two_d, (int(td_point[0][0][0]),int(td_point[0][0][1])), 8, (255,25,0), 1)\n",
    "\n",
    "\n",
    "        for a in dct.values():\n",
    "            for b in dct.values():\n",
    "#                 print((a[0], a[1]),(b[0], b[1]))\n",
    "                \n",
    "                D = int(dist.euclidean((a[0], a[1]),(b[0], b[1])))\n",
    "                line_center_x = int((a[0] + b[0]) / 2)\n",
    "                line_center_y = int((a[1] + b[1]) / 2)\n",
    "                \n",
    "                a_width = a[2][0][3] - a[2][0][1]\n",
    "                a_length = a[2][0][2] - a[2][0][0]\n",
    "                \n",
    "                b_width = b[2][0][3] - b[2][0][1]\n",
    "                b_length = b[2][0][2] - b[2][0][0]\n",
    "#                 print(D)\n",
    "                if a != b:#0 < D < 100:\n",
    "                            \n",
    "                    #check areaoverlap\n",
    "                    polygon = Polygon([(int(b[2][0][3] + (b_length - (0.5*b_width))),int(b[2][0][2] + (0.35 * b_length))),(int(b[2][0][1] - (b_length - (0.5*b_width))),int(b[2][0][2] + (0.35 * b_length))),(int(b[2][0][1] - (b_length - (0.5*b_width))),int(b[2][0][0] + (0.65 * b_length))),(int(b[2][0][3] + (b_length - (0.5*b_width))),int(b[2][0][0] + (0.65 * b_length)))])\n",
    "                    other_polygon = Polygon([(int(a[2][0][3] + (a_length - (0.5*a_width))),int(a[2][0][2] + (0.35 * a_length))),(int(a[2][0][1] - (a_length - (0.5*a_width))),int(a[2][0][2] + (0.35 * a_length))),(int(a[2][0][1] - (a_length - (0.5*a_width))),int(a[2][0][0] + (0.65 * a_length))),(int(a[2][0][3] + (a_length - (0.5*a_width))),int(a[2][0][0] + (0.65 * a_length)))])\n",
    "                    intersection = polygon.intersection(other_polygon)\n",
    "                    overlap = (int((intersection.area * 2)/(polygon.area + other_polygon.area)*100))\n",
    "#                     print(overlap)\n",
    "                    if overlap > 50:\n",
    "                        \n",
    "#                         cv2.rectangle(img,(a[2][0][1],a[2][0][0]),(a[2][0][3],a[2][0][2]),(0,0,255),1)\n",
    "#                         cv2.rectangle(img,(b[2][0][1],b[2][0][0]),(b[2][0][3],b[2][0][2]),(0,0,255),1)\n",
    "                        \n",
    "                        cv2.ellipse(img, (b[0],b[2][0][2]), ((b[2][0][2] - b[2][0][0]),int((b[2][0][2] - b[2][0][0])/3)), 0, 0,360, (0,0,255), 1) \n",
    "                        cv2.ellipse(img, (a[0],a[2][0][2]), ((a[2][0][2] - a[2][0][0]),int((a[2][0][2] - a[2][0][0])/3)), 0, 0,360, (0,0,255), 1)\n",
    "\n",
    "                        cv2.circle(img, (b[0],b[1]), 2, (0,0,255), -1)\n",
    "                        cv2.circle(img, (a[0],a[1]), 2, (0,0,255), -1)\n",
    "                        cv2.line(img, (a[0], a[1]),(b[0], b[1]), (0,0,255),1)\n",
    "#                         cv2.putText(img, str(D), (line_center_x, line_center_y),cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0,0,255), 1)\n",
    "                    \n",
    "#                         pt = np.float32([b[0], b[1]]).reshape(1, 1, -1)\n",
    "#                         td_point_b = cv2.perspectiveTransform(pt, h)\n",
    "#                         cv2.circle(two_d, (int(td_point_b[0][0][0]),int(td_point_b[0][0][1])), 3, (0,0,255), -1)\n",
    "#                         cv2.circle(two_d, (int(td_point_b[0][0][0]),int(td_point_b[0][0][1])), 8, (0,0,255), 1)\n",
    "                    \n",
    "#                         pt = np.float32([a[0], a[1]]).reshape(1, 1, -1)\n",
    "#                         td_point_a = cv2.perspectiveTransform(pt, h)\n",
    "#                         cv2.circle(two_d, (int(td_point_a[0][0][0]),int(td_point_a[0][0][1])), 3, (0,0,255), -1)\n",
    "#                         cv2.circle(two_d, (int(td_point_a[0][0][0]),int(td_point_a[0][0][1])), 8, (0,0,255), 1)\n",
    "#                         cv2.line(two_d, (int(td_point_a[0][0][0]),int(td_point_a[0][0][1])),(int(td_point_b[0][0][0]),int(td_point_b[0][0][1])), (0,0,255),1)\n",
    "    \n",
    "    \n",
    "    \n",
    "                    else:\n",
    "                        cv2.rectangle(img,(b[2][0][1],b[2][0][0]),(b[2][0][3],b[2][0][2]),(255,25,0),1)\n",
    "                        cv2.circle(img, (b[0],b[1]), 2, (255,25,0), -1)\n",
    "                        cv2.rectangle(img,(a[2][0][1],a[2][0][0]),(a[2][0][3],a[2][0][2]),(255,25,0),1)\n",
    "                        cv2.circle(img, (a[0],a[1]), 2, (255,25,0), -1) \n",
    "#                         cv2.ellipse(img, (b[0],b[2][0][2]), ((b[2][0][2] - b[2][0][0]),int((b[2][0][2] - b[2][0][0])/3)), 0, 0,360, (255,0,0), 1) \n",
    "#                         cv2.ellipse(img, (a[0],a[2][0][2]), ((a[2][0][2] - a[2][0][0]),int((a[2][0][2] - a[2][0][0])/3)), 0, 0,360, (255,0,0), 1)\n",
    "\n",
    "                        \n",
    "                        \n",
    "        cv2.imshow(\"preview\", img)\n",
    "#         cv2.imshow(\"2d\", two_d)\n",
    "        out.write(img)\n",
    "#         out_2d.write(two_d)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key & 0xFF == ord('q'):\n",
    "            out.release()\n",
    "            out_2d.release()\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184\n",
      "187\n",
      "650\n",
      "1070\n",
      "538\n",
      "597\n",
      "635\n",
      "1189\n",
      "206\n",
      "1309\n",
      "1199\n",
      "1308\n"
     ]
    }
   ],
   "source": [
    "for x in dct.values():\n",
    "    print(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_src = np.float32([517, 7, 1361, 27, 1087, 767, 0, 457]).reshape(4, 1, -1)\n",
    "pts_dst = np.float32([0, 0, 336, 0, 0, 388, 336, 388]).reshape(4, 1, -1)\n",
    "h = cv2.findHomography(pts_src, pts_dst)[0]\n",
    "a = np.float32([52, 376]).reshape(1, 1, -1)\n",
    "T_dst = cv2.perspectiveTransform(a, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 52.]],\n",
       "\n",
       "       [[376.]]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.float32([52, 376]).reshape(2, 1, -1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 517.,    7.]],\n",
       "\n",
       "       [[1361.,   27.]],\n",
       "\n",
       "       [[1087.,  767.]],\n",
       "\n",
       "       [[   0.,  457.]]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pts_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0.,   0.]],\n",
       "\n",
       "       [[336.,   0.]],\n",
       "\n",
       "       [[  0., 388.]],\n",
       "\n",
       "       [[336., 388.]]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pts_dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.2.0) C:\\projects\\opencv-python\\opencv\\modules\\core\\src\\matmul.dispatch.cpp:531: error: (-215:Assertion failed) scn + 1 == m.cols in function 'cv::perspectiveTransform'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-34a77f0e41e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperspectiveTransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpts_source\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.2.0) C:\\projects\\opencv-python\\opencv\\modules\\core\\src\\matmul.dispatch.cpp:531: error: (-215:Assertion failed) scn + 1 == m.cols in function 'cv::perspectiveTransform'\n"
     ]
    }
   ],
   "source": [
    "dst = cv2.perspectiveTransform(pts_source,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((406, 682), (608, 753))"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(int(b[2][0][1] - (b_length - (0.5*b_width))),int(b[2][0][0] + (0.65 * b_length))),(int(b[2][0][3] + (b_length - (0.5*b_width))),int(b[2][0][2] + (0.35 * b_length)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((406.0, 682.65), (608.0, 753.35))"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(b[2][0][1] - (b_length - (0.5*b_width)),b[2][0][0] + (0.65 * b_length)),(b[2][0][3] + (b_length - (0.5*b_width)),b[2][0][2] + (0.35 * b_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((406, 682), (608, 753), (608, 682), (406, 753))"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(int(b[2][0][1] - (b_length - (0.5*b_width))),int(b[2][0][0] + (0.65 * b_length))),(int(b[2][0][3] + (b_length - (0.5*b_width))),int(b[2][0][2] + (0.35 * b_length))),(int(b[2][0][3] + (b_length - (0.5*b_width))),int(b[2][0][0] + (0.65 * b_length))),(int(b[2][0][1] - (b_length - (0.5*b_width))),int(b[2][0][2] + (0.35 * b_length)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((608, 682), (406, 753))"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "(int(b[2][0][3] + (b_length - (0.5*b_width))),int(b[2][0][0] + (0.65 * b_length))),(int(b[2][0][1] - (b_length - (0.5*b_width))),int(b[2][0][2] + (0.35 * b_length)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "406 682 608 753\n"
     ]
    }
   ],
   "source": [
    "print(int(a[2][0][1] - (a_length - (0.5*a_width))),\n",
    "int(a[2][0][0] + (0.65 * a_length)),\n",
    "int(a[2][0][3] + (a_length - (0.5*a_width))),\n",
    "int(a[2][0][2] + (0.35 * a_length)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"261.35999999999996\" height=\"104.36000000000001\" viewBox=\"413.32 222.32 261.35999999999996 104.36000000000001\" preserveAspectRatio=\"xMinYMin meet\"><g transform=\"matrix(1,0,0,-1,0,549.0)\"><path fill-rule=\"evenodd\" fill=\"#ff3333\" stroke=\"#555555\" stroke-width=\"2.0\" opacity=\"0.6\" d=\"M 423.0,232.0 L 665.0,317.0 L 423.0,317.0 L 665.0,232.0 L 423.0,232.0 z\" /></g></svg>"
      ],
      "text/plain": [
       "<shapely.geometry.polygon.Polygon at 0x1f983820908>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((760, 76), (646, 76), (646, 37), (760, 37))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(int(b[2][0][3] + (b_length - (0.5*b_width))),int(b[2][0][2] + (0.35 * b_length))),(int(b[2][0][1] - (b_length - (0.5*b_width))),int(b[2][0][2] + (0.35 * b_length))),(int(b[2][0][1] - (b_length - (0.5*b_width))),int(b[2][0][0] + (0.65 * b_length))),(int(b[2][0][3] + (b_length - (0.5*b_width))),int(b[2][0][0] + (0.65 * b_length)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"123.11999999999989\" height=\"100.0\" viewBox=\"641.44 32.44 123.11999999999989 48.120000000000005\" preserveAspectRatio=\"xMinYMin meet\"><g transform=\"matrix(1,0,0,-1,0,113.0)\"><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"2.0\" opacity=\"0.6\" d=\"M 760.0,76.0 L 646.0,76.0 L 646.0,37.0 L 760.0,37.0 L 760.0,76.0 z\" /></g></svg>"
      ],
      "text/plain": [
       "<shapely.geometry.polygon.Polygon at 0x1f9839a2808>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polygon = Polygon([(int(b[2][0][3] + (b_length - (0.5*b_width))),int(b[2][0][2] + (0.35 * b_length))),(int(b[2][0][1] - (b_length - (0.5*b_width))),int(b[2][0][2] + (0.35 * b_length))),(int(b[2][0][1] - (b_length - (0.5*b_width))),int(b[2][0][0] + (0.65 * b_length))),(int(b[2][0][3] + (b_length - (0.5*b_width))),int(b[2][0][0] + (0.65 * b_length)))])\n",
    "polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11900.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersection.area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18012.0, 16200.0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polygon.area, other_polygon.area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [571, 351, [(280, 534, 423, 608)]],\n",
       " 1: [1123, 529, [(441, 1082, 618, 1164)]],\n",
       " 3: [125, 650, [(581, 88, 720, 162)]],\n",
       " 4: [527, 186, [(130, 507, 242, 548)]],\n",
       " 5: [579, 198, [(139, 563, 258, 596)]],\n",
       " 6: [625, 86, [(39, 605, 134, 645)]],\n",
       " 7: [241, 184, [(108, 217, 261, 265)]],\n",
       " 8: [1008, 56, [(10, 980, 103, 1037)]],\n",
       " 9: [155, 252, [(159, 126, 345, 185)]],\n",
       " 10: [691, 33, [(0, 674, 66, 708)]],\n",
       " 11: [771, 23, [(2, 762, 45, 781)]],\n",
       " 12: [507, 667, [(617, 459, 718, 555)]]}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((683, 7), (711, 75))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(b[2][0][1],b[2][0][0]),(b[2][0][3],b[2][0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(252, 7, 392, 63)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(box[3] - box[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 9)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((b[2][0][3] - b[2][0][1]),int((b[2][0][3] - b[2][0][1])/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(605, 509, 717, 574)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(b[2][0][3] - b[2][0][1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-70.69326 173.78682]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pts_src = np.float32([517, 7, 1361, 27, 1245, 767, 19,763,5,283, 503,7]).reshape(4, 1, -1)\n",
    "inp = cv2.imread('sample_vid.png')\n",
    "out = cv2.imread('2d.jpg')\n",
    "\n",
    "pts_src = np.float32([517, 7, 1361, 27, 1245, 767, 19,763,5,283]).reshape(5, 1, -1)\n",
    "pts_dst = np.float32([0, 0, 336, 0, 336, 388,0, 388,0,186 ]).reshape(5, 1, -1)\n",
    "h = cv2.findHomography(pts_src, pts_dst,cv2.RANSAC)[0]\n",
    "\n",
    "in_pt = np.float32([125, 275]).reshape(1, 1, -1)\n",
    "out_pt = cv2.perspectiveTransform(in_pt, h)\n",
    "\n",
    "cv2.circle(inp, (int(in_pt[0][0][0]),int(in_pt[0][0][1])), 5, (255,25,0), -1)\n",
    "cv2.circle(out, (int(out_pt[0][0][0]),int(out_pt[0][0][1])), 5, (255,25,0), -1)\n",
    "print(out_pt)\n",
    "cv2.imwrite('in.png',inp)\n",
    "cv2.imwrite('out.png',out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_pt[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 517.,    7.]],\n",
       "\n",
       "       [[1361.,   27.]],\n",
       "\n",
       "       [[1245.,  767.]],\n",
       "\n",
       "       [[  19.,  763.]],\n",
       "\n",
       "       [[   5.,  283.]],\n",
       "\n",
       "       [[ 503.,    7.]]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pts_src"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
